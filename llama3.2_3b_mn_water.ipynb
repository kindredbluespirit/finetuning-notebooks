{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pca.state.mn.us/air-water-land-climate/water-quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/.cache/uv/archive-v0/WFBFj9Evhjjky68nZNXvH/bin/python\n",
      "/usr/bin/uv\n",
      "/home/user/unshared/finetuning-notebooks\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!which uv\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 395ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.20ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 15ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install git+https://github.com/unslothai/unsloth.git\n",
    "!uv pip install synthetic-data-kit\n",
    "# !uv pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 07-10 23:30:21 [__init__.py:244] Automatically detected platform cuda.\n",
      "Unsloth: Using dtype = torch.bfloat16 for vLLM.\n",
      "Unsloth: vLLM loading unsloth/Llama-3.2-3B-Instruct-bnb-4bit with actual GPU utilization = 68.19%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.6 with VRAM = 11.63 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 192.\n",
      "Unsloth: vLLM's KV Cache can use up to 5.56 GB. Also swap space = 2 GB.\n",
      "vLLM STDOUT: INFO 07-10 23:30:29 [__init__.py:244] Automatically detected platform cuda.\n",
      "Stdout stream ended before readiness message detected.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataprep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SyntheticDataKit\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m generator = \u001b[43mSyntheticDataKit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Choose any model from https://huggingface.co/unsloth\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munsloth/Llama-3.2-3B-Instruct-bnb-4bit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Longer sequence lengths will be slower!\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/WFBFj9Evhjjky68nZNXvH/lib/python3.12/site-packages/unsloth/dataprep/synthetic.py:161\u001b[39m, in \u001b[36mSyntheticDataKit.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, gpu_memory_utilization, float8_kv_cache, conservativeness, token, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(\n\u001b[32m    153\u001b[39m     model_name = \u001b[33m\"\u001b[39m\u001b[33munsloth/Llama-3.1-8B-Instruct-unsloth-bnb-4bit\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m     **kwargs,\n\u001b[32m    160\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSyntheticDataKit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconservativeness\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconservativeness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/WFBFj9Evhjjky68nZNXvH/lib/python3.12/site-packages/unsloth/dataprep/synthetic.py:147\u001b[39m, in \u001b[36mSyntheticDataKit.__init__\u001b[39m\u001b[34m(self, model_name, max_seq_length, gpu_memory_utilization, float8_kv_cache, conservativeness, token, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth: vllm_process failed to load!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    146\u001b[39m     trial += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from unsloth.dataprep import SyntheticDataKit\n",
    "\n",
    "generator = SyntheticDataKit.from_pretrained(\n",
    "    # Choose any model from https://huggingface.co/unsloth\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "    max_seq_length = 2048, # Longer sequence lengths will be slower!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[31mL VLLM server is not available at \u001b[0m\u001b[4;94mhttp://localhost:8000/v1\u001b[0m\n",
      "\u001b[2KError: \u001b[1;35mHTTPConnectionPool\u001b[0m\u001b[1m(\u001b[0m\u001b[33mhost\u001b[0m=\u001b[32m'localhost'\u001b[0m, \u001b[33mport\u001b[0m=\u001b[1;36m8000\u001b[0m\u001b[1m)\u001b[0m: Max retries exceeded \n",
      "with url: \u001b[35m/v1/\u001b[0m\u001b[95mmodels\u001b[0m \u001b[1m(\u001b[0mCaused by \n",
      "\u001b[1;35mNewConnectionError\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32murllib3.connection.HTTPConnection\u001b[0m\u001b[32m object at \u001b[0m\n",
      "\u001b[32m0x7fd70e835280\u001b[0m\u001b[32m>\u001b[0m\u001b[32m: Failed to establish a new connection: \u001b[0m\u001b[32m[\u001b[0m\u001b[32mErrno 111\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Connection \u001b[0m\n",
      "\u001b[32mrefused'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
      "\u001b[2Kmâ ‹\u001b[0m Checking VLLM server at http://localhost:8000/v1...\n",
      "\u001b[33mTo start the server, run:\u001b[0m\n",
      "\u001b[2K\u001b[1;34mvllm serve meta-llama/Llama-\u001b[0m\u001b[1;36m3.3\u001b[0m\u001b[1;34m-70B-Instruct --port \u001b[0m\u001b[1;36m8000\u001b[0m\n",
      "\u001b[2K\u001b[32mâ ‹\u001b[0m Checking VLLM server at http://localhost:8000/v1...v1...\u001b[0m\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!synthetic-data-kit system-check"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
